{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "kera",
      "language": "python",
      "name": "kera"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "boostFeature.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epsilon-deltta/amazon-review/blob/master/boostFeature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "protective-springer"
      },
      "source": [
        "### import  "
      ],
      "id": "protective-springer"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "christian-fields",
        "outputId": "59a0d638-2799-4f60-c6a5-eafb134448ee"
      },
      "source": [
        "!pip install livelossplot\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten  \n",
        "\n",
        "from keras.layers import Conv2D,MaxPooling1D,MaxPooling2D ,Conv1D\n",
        "\n",
        "from keras.layers import Dropout , BatchNormalization\n",
        "from keras.layers import Embedding , LSTM\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "!pip install livelossplot\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "#### Do once (load , nlp preprocess , build Embedding Matrix ) \n",
        "\n",
        "# in colab\n",
        "# preprocess\n",
        "# embedding\n",
        "# xtr,ytr,xte,yte, embedding_matrix,vocab_size,vector_size = load_data(path)"
      ],
      "id": "christian-fields",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: livelossplot in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (0.5.4)\n",
            "Requirement already satisfied: ipython in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from livelossplot) (7.16.1)\n",
            "Requirement already satisfied: numpy<1.20 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from livelossplot) (1.19.5)\n",
            "Requirement already satisfied: bokeh in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from livelossplot) (2.3.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from livelossplot) (3.3.4)\n",
            "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (8.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (5.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: packaging>=16.8 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (20.8)\n",
            "Requirement already satisfied: tornado>=5.1 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (6.1)\n",
            "Requirement already satisfied: Jinja2>=2.7 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (2.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (3.7.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from Jinja2>=2.7->bokeh->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from packaging>=16.8->bokeh->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: backcall in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (3.0.14)\n",
            "Requirement already satisfied: colorama in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (0.4.4)\n",
            "Requirement already satisfied: pygments in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (2.7.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (51.3.3.post20210118)\n",
            "Requirement already satisfied: traitlets>=4.2 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Using cached jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from jedi>=0.10->ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from matplotlib->livelossplot) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.0\n",
            "Requirement already satisfied: livelossplot in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (0.5.4)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from livelossplot) (3.3.4)\n",
            "Requirement already satisfied: bokeh in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from livelossplot) (2.3.0)\n",
            "Requirement already satisfied: ipython in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from livelossplot) (7.16.1)\n",
            "Requirement already satisfied: numpy<1.20 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from livelossplot) (1.19.5)\n",
            "Requirement already satisfied: tornado>=5.1 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (3.7.4.3)\n",
            "Requirement already satisfied: Jinja2>=2.7 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (2.11.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (5.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: packaging>=16.8 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (20.8)\n",
            "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from bokeh->livelossplot) (8.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from Jinja2>=2.7->bokeh->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from packaging>=16.8->bokeh->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (3.0.14)\n",
            "Requirement already satisfied: jedi>=0.10 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (0.18.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (51.3.3.post20210118)\n",
            "Requirement already satisfied: decorator in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pygments in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (2.7.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (0.4.4)\n",
            "Requirement already satisfied: backcall in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from jedi>=0.10->ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\epsilon\\dev\\anaconda\\envs\\kera\\lib\\site-packages (from matplotlib->livelossplot) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "central-consultancy"
      },
      "source": [
        "### handle data "
      ],
      "id": "central-consultancy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grave-emerald"
      },
      "source": [
        "if not os.path.exists('data'):\n",
        "    os.system('git clone https://github.com/epsilon-deltta/dataset data')\n",
        "    path = './data/amazon-review/'\n",
        "else :\n",
        "    if os.path.exists('data/amazon-review'):\n",
        "        path = './data/amazon-review/'\n",
        "    else:\n",
        "        path = './data/'\n",
        "def load_data(path='./data/'):\n",
        "    testdir  = path + 'test/'\n",
        "    traindir = path + 'train/'\n",
        "\n",
        "    df = [ pd.DataFrame(columns = ['n','review','target']) for _ in range(2)]\n",
        "\n",
        "    for i,path in enumerate([traindir,testdir]):\n",
        "        path = path\n",
        "        label = 'positive'\n",
        "\n",
        "        poslist = [ os.path.join(path,label,name) for name in os.listdir(path+label) ]\n",
        "\n",
        "        label = 'negative' \n",
        "        neglist = [ os.path.join(path,label,name) for name in os.listdir(path+label) ]\n",
        "\n",
        "        sep = os.path.sep\n",
        "\n",
        "        for fpath in poslist :\n",
        "            num = fpath.split(sep)[-1]\n",
        "            with open(fpath,'r') as f :\n",
        "                content = f.read()\n",
        "\n",
        "            item = dict(zip(df[i].columns,[num,content,1] ) )\n",
        "            df[i] = df[i].append(item,ignore_index=True)\n",
        "\n",
        "        for fpath in neglist :\n",
        "            num = fpath.split(sep)[-1]\n",
        "            with open(fpath,'r') as f :\n",
        "                content = f.read()\n",
        "\n",
        "            item = dict(zip(df[i].columns,[num,content,0] ) )\n",
        "            df[i] = df[i].append(item,ignore_index=True)\n",
        "    return df[0].review,df[0].target,df[1].review,df[1].target\n",
        "\n",
        "xtr,ytr,xte,yte = load_data(path)"
      ],
      "id": "grave-emerald",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "engaging-intranet"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
        "from keras.preprocessing import text\n",
        "\n",
        "# - Word Index: keep the most frequent 10k words\n",
        "vocab_size = 10000\n",
        "token = Tokenizer(num_words = vocab_size + 1) # 상위 10000개 단어만 사용\n",
        "\n",
        "token.fit_on_texts(xtr)\n",
        "max_len = 400\n",
        "def preprocess(docs,token,max_len=400):\n",
        "    docs = token.texts_to_sequences(docs)\n",
        "    \n",
        "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "    docs = pad_sequences(docs, maxlen=max_len)\n",
        "    \n",
        "    return docs\n",
        "\n",
        "xtr = preprocess(xtr,token)\n",
        "xte = preprocess(xte,token)"
      ],
      "id": "engaging-intranet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hindu-tulsa"
      },
      "source": [
        "# - Word embedding dimension: 100\n",
        "# vocab_size  = token.num_words # 10000+ 1 \n",
        "vector_size = 100  #100\n",
        "vocab_size = 10001\n",
        "\n",
        "def get_emb_mtr():\n",
        "    wv = pd.read_csv(path+'all.review.vec.txt',sep=' ',skiprows=1,header=None)\n",
        "\n",
        "    wv.set_index(0,inplace=True)\n",
        "    del wv[101]\n",
        "\n",
        "\n",
        "    embedding_matrix = np.zeros((vocab_size, vector_size))\n",
        "\n",
        "    def get_vector(word):\n",
        "        if word in wv.index:\n",
        "            return wv.loc[word]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    num = 0\n",
        "    word_index = [( i,word) for i,word in token.index_word.items()][:10000]\n",
        "    not_used = []\n",
        "    for i,word in word_index: \n",
        "        temp = get_vector(word)\n",
        "        if temp is not None: \n",
        "\n",
        "            embedding_matrix[i] = temp # 해당 단어 위치의 행에 벡터의 값을 저장한다.\n",
        "        else :\n",
        "            not_used.append(word)\n",
        "            num+=1\n",
        "    return embedding_matrix , not_used,num,wv\n",
        "\n",
        "embedding_matrix , not_used,num,wv = get_emb_mtr()"
      ],
      "id": "hindu-tulsa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seeing-meditation"
      },
      "source": [
        "#### preprocess(cleaning) \n",
        "'solar > ' solar # 대부분의 단어가 'solar queen ' 여거에서 파생됨 , 'solar queen ' 책 제목이나 영화이름을 지칭한듯 보인다.\n",
        "laszlo : 이름   \n",
        "battelle : 사람이름   \n",
        "zia : 장소이름    \n",
        "huband : 사람이름  \n",
        "arnhart : 사람이름  \n",
        "groothuis : 사람이름  \n",
        "eddison : 사람이름\n",
        "\n",
        "3rds > thirds"
      ],
      "id": "seeing-meditation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "present-while"
      },
      "source": [
        "xtr = xtr.astype('float')\n",
        "xte = xte.astype('float')\n",
        "ytr = ytr.astype('float')\n",
        "yte = yte.astype('float')"
      ],
      "id": "present-while",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hourly-tenant"
      },
      "source": [
        "### model "
      ],
      "id": "hourly-tenant"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prime-maple"
      },
      "source": [
        "def get_bestpath(pathname):\n",
        "    import re\n",
        "    modelf = re.compile('\\d+[-]')\n",
        "    bestpath = sorted([ fname for fname in os.listdir(pathName) if modelf.match(fname) ],reverse=True)[0]\n",
        "    bestpath = pathName+'/'+bestpath\n",
        "    return bestpath\n",
        "\n",
        "def livetrain(model):\n",
        "    \n",
        "    dirname = model.name\n",
        "    if os.path.exists(dirname):\n",
        "        for name in os.listdir(dirname):\n",
        "            os.remove(dirname+'/'+name)\n",
        "    else :\n",
        "        os.mkdir(dirname)\n",
        "    modelpath= dirname + \"/{epoch:02d}-{val_loss:.4f}-{val_acc:f}.hdf5\"\n",
        "\n",
        "    live  = PlotLossesKeras()\n",
        "    early = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=20)\n",
        "    checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1,patience=20,save_best_only=True)    \n",
        "    \n",
        "    history = model.fit(xtr, ytr, batch_size=200, epochs=70, verbose=1\n",
        "                    ,validation_data=(xval, yval) \\\n",
        "                    ,callbacks=[live,early,checkpointer])\n",
        "    \n",
        "    bestpath = get_bestpath(dirname)\n",
        "    model.load_weights(bestpath)\n",
        "        \n",
        "    print(bestpath)\n",
        "    print(model.evaluate(xte,yte) )"
      ],
      "id": "prime-maple",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diverse-timber"
      },
      "source": [
        "model_name = 'lstmb2'\n",
        "gpus = tf.config.experimental.list_logical_devices('gpu')\n",
        "if len(gpus) > 1:\n",
        "    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "\n",
        "with strategy.scope():\n",
        "\n",
        "    model = Sequential(name = model_name)\n",
        "    e = Embedding(vocab_size, vector_size, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "    model.add(e)\n",
        "    model.add(LSTM(100,activation='tanh'))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Dense(100,kernel_regularizer=tf.keras.regularizers.l2(0.001) ) )\n",
        "    \n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "id": "diverse-timber",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "administrative-parameter"
      },
      "source": [
        "livetrain(model)"
      ],
      "id": "administrative-parameter",
      "execution_count": null,
      "outputs": []
    }
  ]
}